

维护机器数
系统IO问题该如何分析定位
数据的备份和恢复、主备延迟
数据的一致性
故障排查
版本、发布、故障定位等项目与运维工作；

Linux相关知识和程序
Linux下软链接和硬链接的区别
在Linux系统中，链接分为两种，一种是硬链接（Hard link），另一种称为符号链接或软链接（Symbolic Link）。
①默认不带参数的情况下，ln创建的是硬链接，带-s参数的ln命令创建的是软链接。
②硬链接文件与源文件的inode节点号相同，而软链接文件的inode节点号，与源文件不同，
③ln命令不能对目录创建硬链接，但可以创建软链接。对目录的软链接会经常使用到。
④删除软链接文件，对源文件和硬链接文件无任何影响。
⑤删除文件的硬链接文件，对源文件及软链接文件无任何影响。
⑥删除链接文件的源文件，对硬链接文件无影响，会导致其软链接失效（红底白字闪烁状）。
⑦同时删除源文件及其硬链接文件，整个文件才会被真正的删除。
⑧很多硬件设备的快照功能，使用的就是类似硬链接的原理。
⑨软链接可以跨文件系统，硬链接不可以跨文件系统。
LVS、Nginx、HAproxy有什么区别？工作中你怎么选择？
LVS： 是基于四层的转发
HAproxy： 是基于四层和七层的转发，是专业的代理服务器
Nginx： 是WEB服务器，缓存服务器，又是反向代理服务器，可以做七层的转发
区别： LVS由于是基于四层的转发所以只能做端口的转发而基于URL的、基于目录的这种转发LVS就做不了
工作选择：
HAproxy和Nginx由于可以做七层的转发，所以URL和目录的转发都可以做在很大并发量的时候我们就要选择LVS，像中小型公司的话并发量没那么大选择HAproxy或者Nginx足已，由于HAproxy由是专业的代理服务器配置简单，所以中小型企业推荐使用HAproxy
讲一下Keepalived的工作原理？
在一个虚拟路由器中，只有作为MASTER的VRRP路由器会一直发送VRRP通告信息,
BACKUP不会抢占MASTER，除非它的优先级更高。当MASTER不可用时(BACKUP收不到通告信息)
多台BACKUP中优先级最高的这台会被抢占为MASTER。这种抢占是非常快速的(<1s)，以保证服务的连续性
于安全性考虑，VRRP包使用了加密协议进行加密。BACKUP不会发送通告信息，只会接收通告信息
讲述一下LVS三种模式的工作过程？
LVS 有三种负载均衡的模式，分别是VS/NAT（nat 模式） VS/DR(路由模式) VS/TUN（隧道模式）
一、NAT模式（VS-NAT）
原理：就是把客户端发来的数据包的IP头的目的地址，在负载均衡器上换成其中一台RS的IP地址
并发至此RS来处理,RS处理完后把数据交给负载均衡器,负载均衡器再把数据包原IP地址改为自己的IP
将目的地址改为客户端IP地址即可期间,无论是进来的流量,还是出去的流量,都必须经过负载均衡器
优点：集群中的物理服务器可以使用任何支持TCP/IP操作系统，只有负载均衡器需要一个合法的IP地址
缺点：扩展性有限。当服务器节点（普通PC服务器）增长过多时,负载均衡器将成为整个系统的瓶颈
因为所有的请求包和应答包的流向都经过负载均衡器。当服务器节点过多时
大量的数据包都交汇在负载均衡器那，速度就会变慢！
二、IP隧道模式（VS-TUN）
原理：首先要知道，互联网上的大多Internet服务的请求包很短小，而应答包通常很大
那么隧道模式就是，把客户端发来的数据包，封装一个新的IP头标记(仅目的IP)发给RS
RS收到后,先把数据包的头解开,还原数据包,处理后,直接返回给客户端,不需要再经过
负载均衡器。注意,由于RS需要对负载均衡器发过来的数据包进行还原,所以说必须支持
IPTUNNEL协议，所以,在RS的内核中,必须编译支持IPTUNNEL这个选项
优点：负载均衡器只负责将请求包分发给后端节点服务器，而RS将应答包直接发给用户
所以，减少了负载均衡器的大量数据流动，负载均衡器不再是系统的瓶颈，就能处理很巨大的请求量
这种方式，一台负载均衡器能够为很多RS进行分发。而且跑在公网上就能进行不同地域的分发。
缺点：隧道模式的RS节点需要合法IP，这种方式需要所有的服务器支持”IP Tunneling”
(IP Encapsulation)协议，服务器可能只局限在部分Linux系统上
三、直接路由模式（VS-DR）
原理：负载均衡器和RS都使用同一个IP对外服务但只有DR对ARP请求进行响应
所有RS对本身这个IP的ARP请求保持静默也就是说,网关会把对这个服务IP的请求全部定向给DR
而DR收到数据包后根据调度算法,找出对应的RS,把目的MAC地址改为RS的MAC（因为IP一致）
并将请求分发给这台RS这时RS收到这个数据包,处理完成之后，由于IP一致，可以直接将数据返给客户
则等于直接从客户端收到这个数据包无异,处理后直接返回给客户端
由于负载均衡器要对二层包头进行改换,所以负载均衡器和RS之间必须在一个广播域
也可以简单的理解为在同一台交换机上
优点：和TUN（隧道模式）一样，负载均衡器也只是分发请求，应答包通过单独的路由方法返回给客户端
与VS-TUN相比，VS-DR这种实现方式不需要隧道结构，因此可以使用大多数操作系统做为物理服务器。
缺点：（不能说缺点，只能说是不足）要求负载均衡器的网卡必须与物理网卡在一个物理段上。

同步，异步，阻塞，非阻塞等关系轻松理解
在IT领域对于同步、异步、阻塞、非阻塞是很多人理解不好的几个概念。
本文试图从最简单的角度去解读他们之间的关系，下面开门见山说明他们的关系。
本质上并没有关系
同步与异步是关于指令执行顺序的。
阻塞非阻塞是关于线程与进程的。
两者本身并没有必然的关联系。
他们产生关系的领域CPU中断与IO
没有IO操作，所有的代码基本都是同步的
有了IO操作后，如果没有多进程多线程，所有代码还是同步的
有了IO操作，有了多进程多线程，代码才有了异步的可能性，同时也产生了阻塞与非阻塞
同步与异步
同步是指代码调用IO操作时，必须等待IO操作完成才返回的调用方式。
异步是指代码调用IO操作时，不必等IO操作完成就返回的调用方式。
同步是最原始的调用方式。
异步则需要多线程，多CPU或者非阻塞IO的支持。
阻塞与非阻塞
阻塞是指调用线程或者进程被操作系统挂起。
非阻塞是指调用线程或者进程不会被操作系统挂起。
异步，同步与 IO，线程，进程，阻塞，非阻塞等的关系
单线程
只有同步，等待IO（Programmed I/O)。
如果有多线程，那么这些IO都是阻塞的。
多线程(多进程)让非阻塞成为可能
默认同步，IO调用仍可以是阻塞的。
异步在多线程中成为可能。IO也可以多路复用，从而对IO进行异步调用可以不产生阻塞。
而最常用的异步调用是源于异步IO。
阻塞与非阻塞
同步IO必定是阻塞IO（如果是多线程的环境的话，单线程无所谓阻塞）。
因为同步要求IO处理是线性的，所以当IO调用时必定会阻塞进程或者线程。
异步IO也一定就是非阻塞IO。
异步在代码上的处理
对于异步，在不同的语言在实现上的处理是不同的。
最基本的形式回调函数
对异步影响最原始的处理方式是回调函数，这种方式基本上可以认为是汇编语言就开始采用的方式。
因为汇编语言对中断的影响本身就是一种回调函数，而中断本身就是一种IO操作。
后来的很多编译语言都是基于回调函数形式的。包括C，C++等
其它对回调的改进 (yield => promise => async/await)
异步调用出现后，会导致代码的执行不再那么直观。
不同的语言针对异步调用引入不少代码同步化的机制。
最常用的机制就是promise , yield, async/await，事件通知
ruby是较早引入yield的语言。
javascript是使用promise被使用的最多语言
async/await源于.net
目前来看最完备的同步化解决方案是async/await 机制
阻塞与非阻塞
同步代码调用的是同步IO，也就是阻塞IO。（理论上也存在非阻塞IO的可能，但实际上似乎并没有）
异步代码不一定调用的是异步IO，也可以是同步的IO。所以异步调用不阻塞自己的线程，但是不表示IO线程一定是不阻塞的。因为异步调用的形式并不直接与IO关联，中间还有OS与编程语言参与。所以有异步调用时我们并不能确定调用与IO之间的关系。
同步、异步和IO+代码
同步异步分IO与代码两种。
在IO上同步IO等于阻塞IO，异步IO等于非阻塞IO
在代码上同步代码等同于调用同步IO，等同于调用阻塞IO；但并不表示异步代码一定有异步IO调用，从而也无法确定是不是一定是非阻塞IO。
总结
文章的分析了异步，同步，阻塞，非阻塞，单进程，多进程，同步代码，异步代码的同步化等的概念与关系。
由于他们之间的关系是比较复杂的，未来也存着的技术革新带来的可能性。
希望这篇文章能帮助你更好的去理解他们，并在实际过程中灵活准确的应用。
也欢迎反馈文章中的错误。

进程和线程、协程的区别：
进程
进程是系统资源分配的最小单位, 系统由一个个进程(程序)组成
一般情况下，包括文本区域（text region）、数据区域（data region）和堆栈（stack region）。
	文本区域存储处理器执行的代码
	数据区域存储变量和进程执行期间使用的动态分配的内存；
	堆栈区域存储着活动过程调用的指令和本地变量。
因此进程的创建和销毁都是相对于系统资源,所以是一种比较昂贵的操作。
进程有三个状态:
1.	等待态：等待某个事件的完成；
2.	就绪态：等待系统分配处理器以便运行；
3.	运行态：占有处理器正在运行。
进程是抢占式的争夺CPU运行自身,而CPU单核的情况下同一时间只能执行一个进程的代码,但是多进程的实现则是通过CPU飞快的切换不同进程,因此使得看上去就像是多个进程在同时进行.
通信问题:    由于进程间是隔离的,各自拥有自己的内存内存资源, 因此相对于线程比较安全, 所以不同进程之间的数据只能通过 IPC(Inter-Process Communication) 进行通信共享.
线程
	线程属于进程
	线程共享进程的内存地址空间
	线程几乎不占有系统资源
通信问题:   进程相当于一个容器,而线程而是运行在容器里面的,因此对于容器内的东西,线程是共同享有的,因此线程间的通信可以直接通过全局变量进行通信,但是由此带来的例如多个线程读写同一个地址变量的时候则将带来不可预期的后果,因此这时候引入了各种锁的作用,例如互斥锁等。
同时多线程是不安全的,当一个线程崩溃了,会导致整个进程也崩溃了,即其他线程也挂了,
但多进程而不会,一个进程挂了,另一个进程依然照样运行。
	进程是系统分配资源的最小单位
	线程是CPU调度的最小单位
	由于默认进程内只有一个线程,所以多核CPU处理多进程就像是一个进程一个核心
线程和进程的上下文切换
进程切换分3步:
1.	切换页目录以使用新的地址空间
2.	切换内核栈
3.	切换硬件上下文
而线程切换只需要第2、3步,因此进程的切换代价比较大
协程
	协程是属于线程的。协程程序是在线程里面跑的，因此协程又称微线程和纤程等
	协没有线程的上下文切换消耗。协程的调度切换是用户(程序员)手动切换的,因此更加灵活,因此又叫用户空间线程.
	原子操作性。由于协程是用户调度的，所以不会出现执行一半的代码片段被强制中断了，因此无需原子操作锁。
进程多与线程比较
线程是指进程内的一个执行单元,也是进程内的可调度实体。线程与进程的区别:
1) 地址空间:线程是进程内的一个执行单元，进程内至少有一个线程，它们共享进程的地址空间，而进程有自己独立的地址空间
2) 资源拥有:进程是资源分配和拥有的单位,同一个进程内的线程共享进程的资源
3) 线程是处理器调度的基本单位,但进程不是
4) 二者均可并发执行
5) 每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口，但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制
协程多与线程进行比较
1) 一个线程可以多个协程，一个进程也可以单独拥有多个协程，这样python中则能使用多核CPU。
2) 线程进程都是同步机制，而协程则是异步
3) 协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态
协程的实现：迭代器和生成器
	迭代器： 实现了迭代接口的类,接口函数例如:current,key,next,rewind,valid。迭代器最基本的规定了对象可以通过next返回下一个值，而不是像数组，列表一样一次性返回。语言实现：在Java的foreach遍历迭代器对(数组)，Python的for遍历迭代器对象(tuple，list，dist)。
	生成器： 使用 yield 关键字的函数,可以多次返回值，生成器实际上也算是实现了迭代器接口(协议)。即生成器也可通过next返回下一个值。
协程举例：在Python中，使用了yield的函数为生成器函数，即可以多次返回值。则生成器可以暂停一下，转而执行其他代码，再回来继续执行函数往下的代码。
进程的状态：
Linux 中进程有哪几种状态？在 ps 显示出来的信息中，分别用什么符号表示的？
答案：
（1）、不可中断状态：进程处于睡眠状态，但是此刻进程是不可中断的。不可中断， 指进程不响应异步信号。
（2）、暂停状态/跟踪状态：向进程发送一个 SIGSTOP 信号，它就会因响应该信号 而进入 TASK_STOPPED 状态;当进程正在被跟踪时，它处于 TASK_TRACED 这个特殊的状态。
“正在被跟踪”指的是进程暂停下来，等待跟踪它的进程对它进行操作。
（3）、就绪状态：在 run_queue 队列里的状态
（4）、运行状态：在 run_queue 队列里的状态
（5）、可中断睡眠状态：处于这个状态的进程因为等待某某事件的发生（比如等待 socket 连接、等待信号量），而被挂起
（6）、zombie 状态（僵尸）：父亲没有通过 wait 系列的系统调用会顺便将子进程的尸体（task_struct）也释放掉
（7）、退出状态
D 不可中断 Uninterruptible（usually IO）
R 正在运行，或在队列中的进程
S 处于休眠状态
T 停止或被追踪
Z 僵尸进程
W 进入内存交换（从内核 2.6 开始无效）
X 死掉的进程

io问题故障排查:





MySQL
MySQL主从复制原理：
	MySQL 主从复制概念
MySQL 主从复制是指数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点。MySQL 默认采用异步复制方式，这样从节点不用一直访问主服务器来更新自己的数据，数据的更新可以在远程连接上进行，从节点可以复制主数据库中的所有数据库或者特定的数据库，或者特定的表。
	MySQL 主从复制原理

MySQL主从复制涉及到三个线程，一个运行在主节点（log dump thread），其余两个(I/O thread, SQL thread)运行在从节点，如下图所示:

 
l 主节点 binary log dump 线程
当从节点连接主节点时，主节点会创建一个log dump 线程，用于发送bin-log的内容。在读取bin-log中的操作时，此线程会对主节点上的bin-log加锁，当读取完成，甚至在发动给从节点之前，锁会被释放。

l 从节点I/O线程
当从节点上执行`start slave`命令之后，从节点会创建一个I/O线程用来连接主节点，请求主库中更新的bin-log。I/O线程接收到主节点binlog dump 进程发来的更新之后，保存在本地relay-log中。

l 从节点SQL线程
SQL线程负责读取relay log中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。

对于每一个主从连接，都需要三个进程来完成。当主节点有多个从节点时，主节点会为每一个当前连接的从节点建一个binary log dump 进程，而每个从节点都有自己的I/O进程，SQL进程。从节点用两个线程将从主库拉取更新和执行分成独立的任务，这样在执行同步数据任务的时候，不会降低读操作的性能。比如，如果从节点没有运行，此时I/O进程可以很快从主节点获取更新，尽管SQL进程还没有执行。如果在SQL进程执行之前从节点服务停止，至少I/O进程已经从主节点拉取到了最新的变更并且保存在本地relay日志中，当服务再次起来之后，就可以完成数据的同步。

要实施复制，首先必须打开Master 端的binary log（bin-log）功能，否则无法实现。
因为整个复制过程实际上就是Slave 从Master 端获取该日志然后再在自己身上完全顺序的执行日志中所记录的各种操作。如下图所示：
复制的基本过程如下：
	从节点上的I/O 进程连接主节点，并请求从指定日志文件的指定位置（或者从最开始的日志）之后的日志内容；
	主节点接收到来自从节点的I/O请求后，通过负责复制的I/O进程根据请求信息读取指定日志指定位置之后的日志信息，返回给从节点。返回信息中除了日志所包含的信息之外，还包括本次返回的信息的bin-log file 的以及bin-log position；从节点的I/O进程接收到内容后，将接收到的日志内容更新到本机的relay log中，并将读取到的binary log文件名和位置保存到master-info 文件中，以便在下一次读取的时候能够清楚的告诉Master“我需要从某个bin-log 的哪个位置开始往后的日志内容，请发给我”；
	Slave 的 SQL线程检测到relay-log 中新增加了内容后，会将relay-log的内容解析成在祝节点上实际执行过的操作，并在本数据库中执行。

	MySQL 主从复制模式：
MySQL 主从复制默认是异步的模式。MySQL增删改操作会全部记录在binary log中，当slave节点连接master时，会主动从master处获取最新的bin log文件。并把bin log中的sql relay。
l 异步模式（mysql async-mode）
异步模式如下图所示，这种模式下，主节点不会主动push bin log到从节点，这样有可能导致failover的情况下，也许从节点没有即时地将最新的bin log同步到本地。
 
l 半同步模式(mysql semi-sync)
这种模式下主节点只需要接收到其中一台从节点的返回信息，就会commit；否则需要等待直到超时时间然后切换成异步模式再提交；这样做的目的可以使主从数据库的数据延迟缩小，可以提高数据安全性，确保了事务提交后，binlog至少传输到了一个从节点上，不能保证从节点将此事务更新到db中。性能上会有一定的降低，响应时间会变长。如下图所示：
 
半同步模式不是mysql内置的，从mysql 5.5开始集成，需要master 和slave 安装插件开启半同步模式。

l 全同步模式
全同步模式是指主节点和从节点全部执行了commit并确认才会向客户端返回成功。
	GTID复制模式（全局事务ID（Global Transaction ID），是一个已提交事务的编号，并且是一个全局唯一的编号。）
@ 在传统的复制里面，当发生故障，需要主从切换，需要找到binlog和pos点，然后将主节点指向新的主节点，相对来说比较麻烦，也容易出错。在MySQL 5.6里面，不用再找binlog和pos点，我们只需要知道主节点的ip，端口，以及账号密码就行，因为复制是自动的，MySQL会通过内部机制GTID自动找点同步。
@ 多线程复制（基于库），在MySQL 5.6以前的版本，slave的复制是单线程的。一个事件一个事件的读取应用。而master是并发写入的，所以延时是避免不了的。唯一有效的方法是把多个库放在多台slave，这样又有点浪费服务器。在MySQL 5.6里面，我们可以把多个表放在多个库，这样就可以使用多线程复制。
	基于GTID复制实现的工作原理
	主节点更新数据时，会在事务前产生GTID，一起记录到binlog日志中。
	从节点的I/O线程将变更的bin log，写入到本地的relay log中。
	SQL线程从relay log中获取GTID，然后对比本地binlog是否有记录（所以MySQL从节点必须要开启binary log）。
	如果有记录，说明该GTID的事务已经执行，从节点会忽略。
	如果没有记录，从节点就会从relay log中执行该GTID的事务，并记录到bin log。
	在解析过程中会判断是否有主键，如果没有就用二级索引，如果有就用全部扫描
GTID的缺点(限制)
-  不支持非事务引擎;
-  不支持create table ... select 语句复制(主库直接报错);(原理: 会生成两个sql, 一个是DDL创建表SQL, 一个是insert into 插入数据的sql; 由于DDL会导致自动提交, 所以这个sql至少需要两个GTID, 但是GTID模式下, 只能给这个sql生成一个GTID)
该语句实际上被记录为两个单独的事件,一个是创建表,另一个插入数据。当事务执行该语句时,在一些情况下,这两个事件可能接收到相同的事务ID,导致插入的事件被从库跳过。

-  不允许一个SQL同时更新一个事务引擎表和非事务引擎表;
-  在一个复制组中，必须要求统一开启GTID或者是关闭GTID;
-  开启GTID需要重启 (mysql5.7除外);
-  开启GTID后，就不再使用原来的传统复制方式;
-  对于create temporary table 和 drop temporary table语句不支持;
-  不支持sql_slave_skip_counter;


https://blog.csdn.net/mbshqqb/article/details/103870801


tdsql相关：
http://www.uml.org.cn/sjjm/201901312.asp
https://main.qcloudimg.com/raw/3cc780eb2b03f8ea32878ba3eac47eb0.pdf
 
	binlog记录格式：
MySQL 主从复制有三种方式：基于SQL语句的复制（statement-based replication，SBR），基于行的复制（row-based replication，RBR)，混合模式复制（mixed-based replication,MBR)。对应的binlog文件的格式也有三种：STATEMENT,ROW,MIXED。

l Statement-base Replication (SBR)就是记录sql语句在bin log中，Mysql 5.1.4 及之前的版本都是使用的这种复制格式。优点是只需要记录会修改数据的sql语句到binlog中，减少了binlog日志量，节约I/O，提高性能。缺点是在某些情况下，会导致主从节点中数据不一致（比如sleep(),now()等）。
缺点：由于记录的只是执行语句，为了这些语句能在slave上正确运行，因此还必须记录每条语句在执行的时候的 一些相关信息，以保证所有语句能在slave得到和在master端执行时候相同 的结果。另外mysql 的复制,像一些特定函数功能，slave可与master上要保持一致会有很多相关问题(如sleep()函数， last_insert_id()，以及user-defined functions(udf)会出现问题).
使用以下函数的语句也无法被复制：
LOAD_FILE(
UUID(
USER()
FOUND_ROWS()
SYSDATE() (除非启动时启用了 --sysdate-is-now 选项)
同时在INSERT …SELECT 会产生比 RBR 更多的行级锁

Row-based Relication(RBR)是mysql master将SQL语句分解为基于Row更改的语句并记录在bin log中，也就是只记录哪条数据被修改了，修改成什么样。优点是不会出现某些特定情况下的存储过程、或者函数、或者trigger的调用或者触发无法被正确复制的问题。缺点是会产生大量的日志，尤其是修改table的时候会让日志暴增,同时增加bin log同步时间。也不能通过bin log解析获取执行过的sql语句，只能看到发生的data变更。
缺点:所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样可能会产生大量的日志内容,比 如一条update语句，修改多条记录，则binlog中每一条修改都会有记录，这样造成binlog日志量会很大，特别是当执行alter table之类的语句的时候，由于表结构修改，每条记录都发生改变，那么该表每一条记录都会记录到日志中。

Mixedlevel: 是以上两种level的混合使用，一般的语句修改使用statment格式保存binlog，如一些函数，statement无法完成主从复制的操作，则 采用row格式保存binlog,MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志形式，也就是在Statement和Row之间选择 一种.新版本的MySQL中队row level模式也被做了优化，并不是所有的修改都会以row level来记录，像遇到表结构变更的时候就会以statement模式来记录。至于update或者delete等修改数据的语句，还是会记录所有行的变更。


乐观锁和悲观锁：
两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果经常产生冲突，上层应用会不断的进行retry，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适。

悲观锁(Pessimistic Lock)
总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。
乐观锁Optimistic Lock)
总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。

两种锁的使用场景
从上面对两种锁的介绍，我们知道两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。

悲观锁和乐观锁 总结
	悲观锁是在操作数据过程中，限制其他线程，乐观锁实际是对自己的一次校验
	悲观锁适合写多读少：悲观锁会阻止其他线程工作，因此在大量的查询场景中，如果不断加锁就会造成资源消耗
	乐观锁适合写少读多：乐观锁在操作失败时，会进行事务回滚，所以如果数据会频繁的被改动的话，经常回滚或者重试，也会造成资源浪费

悲观锁的实现方式：悲观锁的实现，依靠数据库提供的锁机制。在数据库中，悲观锁的流程如下：
在对数据修改前，尝试增加排他锁。
加锁失败，意味着数据正在被修改，进行等待或者抛出异常。
加锁成功，对数据进行修改，提交事务，锁释放。
如果我们加锁成功，有其他线程对该数据进行操作或者加排他锁的操作，只能等待或者抛出异常。

乐观锁常见的两种实现方式
乐观锁一般会使用版本号机制或CAS算法实现。
1. 版本号机制
一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。

举一个简单的例子：
假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 $100 。
1.	操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 $50（ $100-$50 ）。
2.	在操作员 A 操作的过程中，操作员B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 $20 （ $100-$20 ）。
3.	操作员 A 完成了修改工作，将数据版本号加一（ version=2 ），连同帐户扣除后余额（ balance=$50 ），提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。
4.	操作员 B 完成了操作，也将版本号加一（ version=2 ）试图向数据库提交数据（ balance=$80 ），但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 2 ，数据库记录当前版本也为 2 ，不满足 “ 提交版本必须大于记录当前版本才能执行更新 “ 的乐观锁策略，因此，操作员 B 的提交被驳回。

这样，就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员A 的操作结果的可能。

2. CAS算法
即compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数
	需要读写的内存值 V
	进行比较的值 A
	拟写入的新值 B
当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。

乐观锁的缺点
ABA 问题是乐观锁一个常见的问题
1 ABA 问题
如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 "ABA"问题。
JDK 1.5 以后的 
AtomicStampedReference 类
就提供了此种能力，其中的 
compareAndSet 方法
就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。

2 循环时间长开销大
自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。 如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。

3 只能保证一个共享变量的原子操作
CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了
AtomicReference类
来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用
AtomicReference类
把多个共享变量合并成一个共享变量来操作。

扩展：https://learnku.com/articles/27880
mysql强制索引和禁止某个索引

1、mysql强制使用索引:force index(索引名或者主键PRI)
例如:
select * from table force index(PRI) limit 2;(强制使用主键)
select * from table force index(ziduan1_index) limit 2;(强制使用索引"ziduan1_index")
select * from table force index(PRI,ziduan1_index) limit 2;(强制使用索引"PRI和ziduan1_index")
 
数据库事务的四大特性以及事务的隔离级别

本篇讲诉数据库中事务的四大特性（ACID），并且将会详细地说明事务的隔离级别。
　　如果一个数据库声称支持事务的操作，那么该数据库必须要具备以下四个特性：
⑴ 原子性（Atomicity）
　　原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，这和前面两篇博客介绍事务的功能是一样的概念，因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响。
⑵ 一致性（Consistency）
　　一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。
　　拿转账来说，假设用户A和用户B两者的钱加起来一共是5000，那么不管A和B之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是5000，这就是事务的一致性。
⑶ 隔离性（Isolation）
　　隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。
　　即要达到这么一种效果：对于任意两个并发的事务T1和T2，在事务T1看来，T2要么在T1开始之前就已经结束，要么在T1结束之后才开始，这样每个事务都感觉不到有其他事务在并发地执行。
　　关于事务的隔离性数据库提供了多种隔离级别，稍后会介绍到。
⑷ 持久性（Durability）
　　持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。
　　例如我们在使用JDBC操作数据库时，在提交事务方法后，提示用户事务操作完成，当我们程序执行完成直到看到提示后，就可以认定事务以及正确提交，即使这时候数据库出现了问题，也必须要将我们的事务完全执行完成，否则就会造成我们看到提示事务处理完毕，但是数据库因为故障而没有执行事务的重大错误。
  
　　以上介绍完事务的四大特性(简称ACID)，现在重点来说明下事务的隔离性，当多个线程都开启事务操作数据库中的数据时，数据库系统要能进行隔离操作，以保证各个线程获取数据的准确性，在介绍数据库提供的各种隔离级别之前，我们先看看如果不考虑事务的隔离性，会发生的几种问题：
1，脏读
　　脏读是指在一个事务处理过程里读取了另一个未提交的事务中的数据。
　　当一个事务正在多次修改某个数据，而在这个事务中这多次的修改都还未提交，这时一个并发的事务来访问该数据，就会造成两个事务得到的数据不一致。例如：用户A向用户B转账100元，对应SQL命令如下
    update account set money=money+100 where name=’B’;  (此时A通知B)

    update account set money=money - 100 where name=’A’;
　　当只执行第一条SQL时，A通知B查看账户，B发现确实钱已到账（此时即发生了脏读），而之后无论第二条SQL是否执行，只要该事务不提交，则所有操作都将回滚，那么当B以后再次查看账户时就会发现钱其实并没有转。
2，不可重复读
　　不可重复读是指在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了。
　　例如事务T1在读取某一数据，而事务T2立马修改了这个数据并且提交事务给数据库，事务T1再次读取该数据就得到了不同的结果，发送了不可重复读。
　　不可重复读和脏读的区别是，脏读是某一事务读取了另一个事务未提交的脏数据，而不可重复读则是读取了前一事务提交的数据。
　　在某些情况下，不可重复读并不是问题，比如我们多次查询某个数据当然以最后查询得到的结果为主。但在另一些情况下就有可能发生问题，例如对于同一个数据A和B依次查询就可能不同，A和B就可能打起来了……
3，虚读(幻读)
　　幻读是事务非独立执行时发生的一种现象。例如事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库。而操作事务T1的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务T2中添加的，就好像产生幻觉一样，这就是发生了幻读。
　　幻读和不可重复读都是读取了另一条已经提交的事务（这点就脏读不同），所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据整体（比如数据的个数）。
 
　　现在来看看MySQL数据库为我们提供的四种隔离级别：
　　① Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。
　　② Repeatable read (可重复读)：可避免脏读、不可重复读的发生。
　　③ Read committed (读已提交)：可避免脏读的发生。
　　④ Read uncommitted (读未提交)：最低级别，任何情况都无法保证。
 
　　以上四种隔离级别最高的是Serializable级别，最低的是Read uncommitted级别，当然级别越高，执行效率就越低。像Serializable这样的级别，就是以锁表的方式(类似于Java多线程中的锁)使得其他的线程只能在锁外等待，所以平时选用何种隔离级别应该根据实际情况。在MySQL数据库中默认的隔离级别为Repeatable read (可重复读)。
　　在MySQL数据库中，支持上面四种隔离级别，默认的为Repeatable read (可重复读)；而在Oracle数据库中，只支持Serializable (串行化)级别和Read committed (读已提交)这两种级别，其中默认的为Read committed级别。


		






zookeeper 

1、zookeeper同步状态  延迟  拨测
2、 zookeeper的状态    
3、zookeeper 数据恢复
zookeeper有

Zookeeper做了什么？
1、命名服务2、配置管理3、集群管理4、分布式锁5、队列管理

Zookeeper Server三种角色：Leader，Follower，Observer
Leader是Zookeeper 集群工作机制的核心，主要工作：
a.调度者：集群内部各个服务节点的调度者
b.事务请求：事务请求的唯一调度和处理者，保证集群事务处理的顺序性
Follower主要职责：
a.非事务请求：Follower 直接处理非事务请求，对于事务请求，转发给 Leader
b.Proposal 投票：Leader 上执行事务时，需要 Follower 投票，Leader 才真正执行
c.Leader 选举投票
Observer主要职责：
a.非事务请求：Follower 直接处理非事务请求，对于事务请求，转发给 Leader
Observer 跟 Follower的区别：
a.Follower 参与投票：Leader 选举、Proposal 提议投票（事务执行确认）
b.Observer 不参与投票：只用于提供非事务请求的处理
Zookeeper Server的状态
LOOKING：寻找Leader
LEADING：Leader状态，对应的节点为Leader。
FOLLOWING：Follower状态，对应的节点为Follower。
OBSERVING：Observer状态，对应节点为Observer，该节点不参与Leader选举。


Leader选举概述
　　Leader选举是保证分布式数据一致性的关键所在。当Zookeeper集群中的一台服务器出现以下两种情况之一时，需要进入Leader选举。
　　(1) 服务器初始化启动。
　　(2) 服务器运行期间无法和Leader保持连接。
　　下面就两种情况进行分析讲解。
　　1. 服务器启动时期的Leader选举
　　若进行Leader选举，则至少需要两台机器，这里选取3台机器组成的服务器集群为例。在集群初始化阶段，当有一台服务器Server1启动时，其单独无法进行和完成Leader选举，当第二台服务器Server2启动时，此时两台机器可以相互通信，每台机器都试图找到Leader，于是进入Leader选举过程。选举过程如下
　　(1) 每个Server发出一个投票。由于是初始情况，Server1和Server2都会将自己作为Leader服务器来进行投票，每次投票会包含所推举的服务器的myid和ZXID，使用(myid, ZXID)来表示，此时Server1的投票为(1, 0)，Server2的投票为(2, 0)，然后各自将这个投票发给集群中其他机器。
　　(2) 接受来自各个服务器的投票。集群的每个服务器收到投票后，首先判断该投票的有效性，如检查是否是本轮投票、是否来自LOOKING状态的服务器。
　　(3) 处理投票。针对每一个投票，服务器都需要将别人的投票和自己的投票进行PK，PK规则如下
　　　　· 优先检查ZXID。ZXID比较大的服务器优先作为Leader。
　　　　· 如果ZXID相同，那么就比较myid。myid较大的服务器作为Leader服务器。
　　对于Server1而言，它的投票是(1, 0)，接收Server2的投票为(2, 0)，首先会比较两者的ZXID，均为0，再比较myid，此时Server2的myid最大，于是更新自己的投票为(2, 0)，然后重新投票，对于Server2而言，其无须更新自己的投票，只是再次向集群中所有机器发出上一次投票信息即可。
　　(4) 统计投票。每次投票后，服务器都会统计投票信息，判断是否已经有过半机器接受到相同的投票信息，对于Server1、Server2而言，都统计出集群中已经有两台机器接受了(2, 0)的投票信息，此时便认为已经选出了Leader。
　　(5) 改变服务器状态。一旦确定了Leader，每个服务器就会更新自己的状态，如果是Follower，那么就变更为FOLLOWING，如果是Leader，就变更为LEADING。
　　2. 服务器运行时期的Leader选举
　　在Zookeeper运行期间，Leader与非Leader服务器各司其职，即便当有非Leader服务器宕机或新加入，此时也不会影响Leader，但是一旦Leader服务器挂了，那么整个集群将暂停对外服务，进入新一轮Leader选举，其过程和启动时期的Leader选举过程基本一致。假设正在运行的有Server1、Server2、Server3三台服务器，当前Leader是Server2，若某一时刻Leader挂了，此时便开始Leader选举。选举过程如下
　　(1) 变更状态。Leader挂后，余下的非Observer服务器都会讲自己的服务器状态变更为LOOKING，然后开始进入Leader选举过程。
　　(2) 每个Server会发出一个投票。在运行期间，每个服务器上的ZXID可能不同，此时假定Server1的ZXID为123，Server3的ZXID为122；在第一轮投票中，Server1和Server3都会投自己，产生投票(1, 123)，(3, 122)，然后各自将投票发送给集群中所有机器。

　　(3) 接收来自各个服务器的投票。与启动时过程相同。
　　(4) 处理投票。与启动时过程相同，此时，Server1将会成为Leader。
　　(5) 统计投票。与启动时过程相同。
　　(6) 改变服务器的状态。与启动时过程相同。




什么是事务？
事务（Transaction）是并发控制的基本单位。所谓的事务，它是一个操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位。事务是数据库维护数据一致性的单位，在每个事务结束时，都能保持数据一致性。

、事物的4种隔离级别
隔离级别

读未提交(RU)

读已提交(RC)

可重复读(RR)

串行



简单说一说drop、delete与truncate的区
SQL中的drop、delete、truncate都表示删除，但是三者有一些差别


1、delete和truncate只删除表的数据不删除表的结构
2、速度,一般来说: drop> truncate >delete
3、delete语句是dml,这个操作会放到rollback segement中,事务提交之后才生效;
4、如果有相应的trigger,执行的时候将被触发. truncate,drop是ddl, 操作立即生效,原数据不放到rollback segment中,不能回滚. 操作不触发trigger.


数据库的乐观锁和悲观锁是什么？
数据库管理系统（DBMS）中的并发控制的任务是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。乐观并发控制(乐观锁)和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。
悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作
乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。




1、什么是Redis？简述它的优缺点？

Redis本质上是一个Key-Value类型的内存数据库，很像memcached，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据flush到硬盘上进行保存。

因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。

Redis的出色之处不仅仅是性能，Redis最大的魅力是支持保存多种数据结构，此外单个value的最大限制是1GB，不像 memcached只能保存1MB的数据，因此Redis可以用来实现很多有用的功能。

比方说用他的List来做FIFO双向链表，实现一个轻量级的高性 能消息队列服务，用他的Set可以做高性能的tag系统等等。

另外Redis也可以对存入的Key-Value设置expire时间，因此也可以被当作一 个功能加强版的memcached来用。 Redis的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。

2、Redis相比memcached有哪些优势？

(1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型

(2) redis的速度比memcached快很多

(3) redis可以持久化其数据

3、Redis支持哪几种数据类型？

String、List、Set、Sorted Set、hashes

4、Redis主要消耗什么物理资源？

内存。


1. http是否是有状态的：无状态的，http的返回码指的是一次情况种的执行情况，http本身是无记忆的
2. 讲一下https：http+ssl协议，需要身份校验，https协议又分为3类
3. http版本区别：2.0是基于spdy协议的，服务端可以主动推送客户端可能需要的内容、报文头部做了压缩，开销小；传输内容是二进制而不是文本，错误率更低；
4. tcp流量控制：都是丢包，实现机制就是让对方发的慢一点，少一点；在接收端丢包，避免业务处理不及时
5. tcp拥塞控制：在网络上丢包，避免网络出现拥塞；
6. Linux常用命令：cat、ls、chmod、tail、head、grep、find、tar、df、netsat、ln、cd、cp、mkdir、gzip、tree、pwd等
7. 查看io的命令：top、iostat、vmstat
8. 僵尸进程、孤儿进程（）
9. 进程通信：管道、fifo、消息队列、信号量、共享内存
10. 介绍下事务（原子性（要么全执行、要么全都不执行）、一致性、隔离性（与其他事务无关）、持久性（一旦执行完就改变））
11. 事务隔离级别（读未提交（其他事务未提交的更新结果）、不可重复读（更新提交之后、其他事务才能获取数据更新后的结果）、可重复读（默认，事务过程中对于同一组数据的提取结果是相同的，不管提交还是不提交）、串行化（所有数据库操作顺序执行））
12. 数据库锁
13. 数据库引擎
14. 索引数据结构
15. java内存管理机制
16. 测试理论
17. 登录页面测试：

1. 等价类划分的依据：有效等价类和无效等价类；数值型、条件型、区间型
2. 把一个数的十进制转为二进制
3. 三次握手
4. tcp和udp的区别（tcp是有连接的、tcp有拥塞控制、tcp是一对一的可靠的全双工信道、tcp的头部开销更大）
5. get和post的区别（参数位置、参数长度限制、参数编码样式、浏览器结合（get会主动缓存且返回无害）
6. 输入一个url，中间用到哪些协议和过程（http协议、tcp协议、arp协议、路由选择协议）-url输入、dns解析找到ip、tcp连接建立、发送http请求、服务端处理请求并返回、tcp连接关闭、浏览器解析资源、渲染。
7. 讲一下java的垃圾回收
8. hashmap怎么找到索引（通过hashcode值的计算）
9. hashmap怎么解决哈希冲突的（分离链表，先比较hashcode再比较key；容量达到0.75的时候直接扩容一倍）
10. dns解析过程（先是本地host找、然后本地dns缓存、然后dns本地服务器、然后根服务器；）
11. 长连接和短连接（长连接就是建立一次tcp连接、多次传输数据；有等待消耗部分；短连接）
12. 进程之间的通信方式、读进程和写进程之间的管道
13. 进程和线程的区别
14. 数据库查找一个班级中成绩大于多少的女生的名字
15. 数据库索引
16. http请求方式
17. 测试工具和框架
18. 测试应该掌握的知识
19. http报文，详细一点
20. 乐观锁和悲观锁（乐观锁，假定别人不会修改，等到需要更新的时候再去判断数据是否做过更新；悲观锁假定每一次都被改的）乐观锁常用版本号机制和cas算法（需要读写的值v，进行比较的值a，准备写入的值b）；
21. tcp怎么保证可靠传输
22. 双11的时候如何测试服务器的性能


redis的速度为什么比memcache快
Kubernetes容器
Kubernetes容器和物理机或者虚拟机有什么优点。

	敏捷应用程序的创建和部署：与使用 VM 镜像相比，提高了容器镜像创建的简便性和效率。
	持续开发、集成和部署：通过快速简单的回滚(由于镜像不可变性)，提供可靠且频繁的容器镜像构建和部署。
	关注开发与运维的分离：在构建/发布时而不是在部署时创建应用程序容器镜像，从而将应用程序与基础架构分离。
	可观察性不仅可以显示操作系统级别的信息和指标，还可以显示应用程序的运行状况和其他指标信号。
	跨开发、测试和生产的环境一致性：在便携式计算机上与在云中相同地运行。
	云和操作系统分发的可移植性：可在 Ubuntu、RHEL、CoreOS、本地、Google Kubernetes Engine 和其他任何地方运行。
	以应用程序为中心的管理：提高抽象级别，从在虚拟硬件上运行 OS 到使用逻辑资源在 OS 上运行应用程序。
	松散耦合、分布式、弹性、解放的微服务：应用程序被分解成较小的独立部分，并且可以动态部署和管理 - 而不是在一台大型单机上整体运行。
	资源隔离：可预测的应用程序性能。
	资源利用：高效率和高密度。

同一个Pod 为其组成容器提供了两种共享资源：网络 和 *存储*。
网络
每个 Pod 分配一个唯一的 IP 地址。 Pod 中的每个容器共享网络命名空间，包括 IP 地址和网络端口。 Pod 内的容器 可以使用 
localhost
 互相通信。 当 Pod 中的容器与 Pod 之外 的实体通信时，它们必须协调如何使用共享的网络资源（例如端口）。
存储
一个 Pod 可以指定一组共享存储卷。 Pod 中的所有容器都可以访问共享卷，允许这些容器共享数据。 卷还允许 Pod 中的持久数据保留下来，以防其中的容器需要重新启动。 有关 Kubernetes 如何在 Pod 中实现共享存储的更多信息，请参考卷。

容器的进程监控、日志清理、定时任务（crontab）等如何处理、负载均衡、服务发现、网络调用、

容器的状态怎么监控：容器探针

探针 是由 kubelet 对容器执行的定期诊断。要执行诊断，kubelet 调用由容器实现的 Handler。有三种类型的处理程序：
	ExecAction：在容器内执行指定命令。如果命令退出时返回码为 0 则认为诊断成功。
	TCPSocketAction：对指定端口上的容器的 IP 地址进行 TCP 检查。如果端口打开，则诊断被认为是成功的。
	HTTPGetAction：对指定的端口和路径上的容器的 IP 地址执行 HTTP Get 请求。如果响应的状态码大于等于200 且小于 400，则诊断被认为是成功的。
每次探测都将获得以下三种结果之一：
	成功：容器通过了诊断。
	失败：容器未通过诊断。
	未知：诊断失败，因此不会采取任何行动


pod控制器类型：
pod控制器有多种类型：
ReplicaSet: 代用户创建指定数量的pod副本数量，确保pod副本数量符合预期状态，并且支持滚动式自动扩容和缩容功能。
ReplicaSet主要三个组件组成：
　　（1）用户期望的pod副本数量
　　（2）标签选择器，判断哪个pod归自己管理
　　（3）当现存的pod数量不足，会根据pod资源模板进行新建
帮助用户管理无状态的pod资源，精确反应用户定义的目标数量，但是RelicaSet不是直接使用的控制器，而是使用Deployment。
Deployment：工作在ReplicaSet之上，用于管理无状态应用，目前来说最好的控制器。支持滚动更新和回滚功能，还提供声明式配置。
DaemonSet：用于确保集群中的每一个节点只运行特定的pod副本，通常用于实现系统级后台任务。比如ELK服务
特性：服务是无状态的
服务必须是守护进程
Job：只要完成就立即退出，不需要重启或重建。
Cronjob：周期性任务控制，不需要持续后台运行，
StatefulSet：管理有状态应用

kubernetes故障排障
在微服务环节下，应用的调度链路变得非常长，一个应用不能访问，造成问题的点可能非常多，这时候我们需要有序地对整个集群进行检查，定位问题、发现问题并且解决问题。

假如我们发现一个服务不可访问，首先需要检查集群几个点是否正常？K8S 整个集群是否正常？
 
我们可以通过查看节点是否正常，一是保证 K8S API Server 是正常的，二是可以查看节点集群网络中是否存在节点异常。如果我们在第一步发现哪个节点挂掉了，这时候我们可以重启节点，对节点上的应用进行恢复。假如我们发现这个节点挂掉是因为集群资源不够，这时候我们要及时增加集群节点，否则哪怕是重启集群，可能还是会挂掉。

通过第一步，我们并没有发现集群中的节点有什么问题，我可能需要看到应用本身的部分，我们需要查看应用本身的日志，需要查看涉及的 Pod 日志。执行时可以看到确认两点，一是看 Pod 基础网络是否通畅，通过日志查看这个应用是不是在运行过程中发现一些问题，是不是有一些错误的日志在里面。二是解决在启动时遇到的常见问题。

假设我们发现 Pod 没有错误情况发生，这时候我们可能需要看看 K8S 核心组件，包括 kube-apiserver，kube-scheduler，kube-controller-manager 的日志。这时候我们可以查看 K8S 核心组件的配置，看有没有问题。

第四步工作是检查 Service 是否可以访问，这时候我们需要查看 DNS 或者 kube-proxy 日志，可以很简单的查看 DNS 或者 kube-proxy 有没有报错。有些人习惯性地在某些 Pod 上抓包或者在节点上进行抓包，这种效率是非常低的。

实在没有定位到问题的话，还可以看看每个节点上 Kubelet，如果 Kubelet 上有错误信息发生，可能就是因为这个节点上 Kubelet 发生了一场灾难，需要我们重新做节点。

以上五种情况可以解决集群中大部分的网络、存储和应用本身的异常。核心依赖是本身集群就有监控系统、监控告警系统，通过这种方式直接在我们监控系统中查看集群中是不是有哪个节点异常。假如我们是微服务应用，还可以查看是不是某一个微服务中的某个链路断开了。

 
除了以上谈到的集群故障，我们还会遇到常见的应用故障。

第一种是 Pod 启动后一直处于 Pending 的状态，表示这个 pod 没有被调度到一个节点上。在我们实际场景中，大部分是因为节点上的资源不足引起的。

第二种是使用了 hostPort 导致端口出现冲突，服务无法正常启动。

第三种是如果你的程序在 Waiting 中，则表示这个 pod 已经调试到节点上，但是没有运行起来，通过 kubectl describe <pod-name> 这个命令来查看相关信息。最常见的原因是拉取镜像失败，这个情况在私有云环境中非常常见。
第四种跟我们应用本身使用参数或者应用本身的代码有关系，这里有一个典型的例子——MySQL。我相信有在 K8S 上部署 MySQL 的用户，都可能遇到这个问题。MySQL 在使用时，假如你的磁盘中缓存不足，这时候我们需要查一查 MySQL 的报错，错误信息会很明确地告诉你需要调大参数，这是都是通过 Controller 命令就可以查到的。假如 Pod 一直 restart 的话，我们可能需要查看它之前的日志。

第五种，Service 提供了多个服务和多个 Pod 之间的负载均衡功能。假设你的服务不可访问时，这时候我们需要考量，可以通过 Controller 查看 Service 下有没有挂载具体的 Pod。

 
我们的集群有时候会出现状况，比如我们的 CPU 或者内存不足，导致节点异常、宕机，或者整个集群网络中断、闪断。

如果节点异常，这时候需要快速重启节点，资源不足要增加节点。如果节点频繁抖动导致业务出现漂移，这时候我们会检查一下 Controller-Manager 中的参数，配置响应参数，设置它整个节点状态检测周期。

如果我们发现 K8S 中发生异常，比如我们发现 Controller-Manager 挂了，或者 Cloud-Controller-Manager 挂了，最核心的是查看日志，及时把这些节点重启起来。最核心的需求是我们需要保证关键组件高可用，包括我们需要让这些组件一直保持在多个副本中。

存储和网络是 K8S 整个环境中最容易出问题的地方，一般像网络出现问题，定位它会像其他似的，我们需要由上至下一层层地筛选，在哪一层的网络出现问题。

 

由于 K8S 整个集群的负载是我们平时无法应付的，所以我们要想办法避免问题，我总结以下四点，帮助我们开发者规避集群中可能遇到的情况。

第一点是我们集群搭建起来，真正落地到生产环境中时，我们非常依赖集群中的监控系统，我们需要 Prometheus，需要 Docker 系统，帮助我们实时监控集群中的资源状况。如果哪个节点发生异常，我们需要及时收到通知。

开发者或者运维人员很容易忽略的一点，假设我们集群中部署了一些 Prometheus 或者日志的组件，我们可能会忽略这些系统组件本身会消耗掉一部分系统资源。

当我们节点不断增加，这些系统组件上面会有 overhead ，它还是会消耗资源。如果应用越来越多、Pod 越来越多，这些系统组件也会有更多的资源消耗，如果没有给系统组件足够的资源会导致这些关键系统组件崩溃，我们需要给他们设置合适的资源限制，需要根据集群规模不断地调整。至少保证我们的监控告警系统正常运行。

第二点是很多时候 K8S 往往会暴露出非常多的安全问题，我们要实时关注，及时修复集群中可能出现的问题。

第三点是应用层的优化，当我们应用出现问题时，如果我们想要快速恢复它，一个大前提是我们要保证应用是无状态的，不依赖于任何存储。有状态应用的恢复比无状态应用的恢复起来麻烦得多。无状态应用，我们可以让应用恢复副本数，充分利用 K8S 调度编排的优势，这是和普通传统应用有区别的地方。我们可以通过这种方式避免我们在 K8S 集群中的应用出现问题。

最重要一点，我们需要及时备份集群中的数据，之前我们发生了一场线上灾难，通过备份数据得以进行恢复，没有影响到业务。
如何打造 K8S 高可用架构

 
即使我们有高可用架构，还是避免不了监控、告警和日志的系统组件。这是最典型的 K8S 多节点架构图：

 

K8S 高可用架构包括以下四个步骤：

	建立一个冗余的，可靠的存储层，etcd 集群

	K8S apiserver 的高可用，多节点多副本，apiserver 负载均衡

	kube-scheduler，kube-controller-manager，核心组件支持多副本选主

	重新配置 kubelet 和 kube-proxy，--apiserver 指向 apiserver lb

光有高可用的集群架构只能保证我们 K8S 集群可用，实际上我们最终还是要用自己的应用，我们需要大量依赖日志系统、监控系统、高可用系统，对我们集群中运维实际日志的业务系统进行监控。

如果需要中的日志进行收集，我们可以通过 ELK 这种方案，对所有的 Pod 进行收集。我们可以接入可视化的方案进行查看。刚刚有人提到 Prometheus，Prometheus 本身有 Manager 这样项目，Manager 有非常大的短板，所以在实际过程中有很多开发者都会自己实现。

kubernetes使用案例：
最简单的方案是 KubeSphere® 提供一键式的部署，下面有监控、日志、告警所有的解决方案。


负载均衡 - 一个应用运行多个同样的容器，内部 Service 提供了统一的访问定义，以负载均衡的方式来提供访问。

服务发现 - Service 和 Kube-DNS 结合，只需要通过固定的 Service 名称就可以访问到对应的容器，不需要独立寻找使用服务发现组件。

高可用 - K8S 会检查服务的健康状态，发现异常时会自动尝试重新启动服务，保障正常运行。

滚动升级 - 在升级过程中 K8S 会有规划的挨个容器滚动升级，把升级带来的影响降低到最小。

自动伸缩 - 可以配置策略当容器资源使用较高会自动增加新的容器来分担压力, 当资源使用率降低会回收容器。

快速部署 - 编写好对应的编排脚本, 可以在极短的时间部署一套环境。

资源限制 - 对程序限制最大资源使用量避免抢占资源遇到事故或压力也能从容保障基础服务不受影响。
进一步深入了解 K8S 之后，我们大致确定了会用到如下组件、相关技术和系统：
	应用部署 K8S Deployment，HPA；
	少量基础服务 K8S Daemonset, kube-dns；
	对外服务暴露 K8S Ingress, Traefik, Service；
	网络插件 Flannel；
	监控告警 Heapster, InfluxDB, Grafana, Prometheus；
	管理界面 Kubectl, Dashboard, 自研发布管理系统；
	制作镜像 Jenkins, Maven, Docker；
	镜像仓库 Harbor；
	日志收集 Filebeat, Kafka, ELK。
难点和基本原则
1.	线上服务必须在不间断提供服务的情况下迁移，每个应用按比例切分流量，在确保稳定性的前提下迁移到 K8S 集群中。
2.	DEV 环境可批量上线，QA 和 Production 环境上线需要考虑各应用的版本依赖关系。
3.	初期只上无状态的应用。
4.	对研发 /QA 的影响最小化（尽量不给繁忙的研发 /QA 同学增加工作量）。

参考：https://tech.meituan.com/2019/08/22/kubernetes-cluster-management-practice.html 

Ingress 可以提供负载均衡、SSL 终结和基于名称的虚拟托管

1) 原理问题:  
    Docker底层实现:
       Linux 上的命名空间（Namespaces）、控制组（Control groups）、Union 文件系统（Union file systems）和容器格式（Container format）
   Docker是怎么工作的
      Docker是一个Client-Server结构的系统，Docker守护进程（Docker daemon）运行在主机上， 然后通过Socket连接从客户端访问，守护进程从客户端接受命令并管理运行在主机上的容器。 

k8s的pause容器作用
问题：k8s的pause容器有什么用。是否可以去掉。
关于"暂停"容器讲解比较详细的文章 http://dockone.io/article/2785 。
其提供两个功能，一是提供Pod在Linux中共享命名空间的基础，而是提供Pid Namespace并使用init进程。
命名空间是Linux中对资源隔离的机制，可参见：https://segmentfault.com/a/1190000009732550
隔离的条目很多，如IPC、Network、Mount、PID、User、UTC，通过Cgroup还可以限制CPU、内存等。
因此，我认为是可以去掉的。目前在运行Pod的时候，没并没有添加pause容器。
k8s的pod内容器之间的关系
问题：k8s中的pod内几个容器之间的关系是什么。
我们看k8s官方文档的解释：
一个Pod是一组容器的集合，像豌豆荚于豌豆。提供容器间存储和网络的共享，和一系列运行规范。
原文：https://kubernetes.io/docs/concepts/workloads/pods/pod/
Pod里面的容器共享网络，因此可使用localhost通讯。由于也共享存储，所以可以使用IPC和共享内存进行通讯。
详述kube-proxy原理
问题：详述kube-proxy原理，一个请求是如何经过层层转发落到某个pod上的整个过程。请求可能来自pod也可能来自外部。
kube-proxy部署在每个Node节点上，通过监听集群状态变更，并对本机iptables做修改，从而实现网络路由。 而其中的负载均衡，也是通过iptables的特性实现的。
另外我们需要了解k8s中的网络配置类型，有如下几种：
	hostNetwork Pod使用宿主机上的网络，此时可能端口冲突。
	hostPort 宿主机上的端口与Pod的目标端口映射。
	NodePort 通过Service访问Pod，并给Service分配一个ClusterIP。
rc/rs实现原理
问题：rc/rs功能是怎么实现的。详述从API接收到一个创建rc/rs的请求，到最终在节点上创建pod的全过程，尽可能详细。另外，当一个pod失效时，kubernetes是如何发现并重启另一个pod的？
Replication Controller 可以保证Pod始终处于规定的副本数。
而当前推荐的做法是使用Deployment+ReplicaSet。
ReplicaSet 号称下一代的 Replication Controller，当前唯一区别是RS支持set-based selector。
RC是通过ReplicationManager监控RC和RC内Pod的状态，从而增删Pod，以实现维持特定副本数的功能。
可参见：https://blog.csdn.net/WaltonWang/article/details/62433143
RS也是大致相同
灰色发布在原生k8s中的实现
问题：灰度发布是什么。如何使用k8s现有的资源实现灰度发布。
k8s 创建一个pod的详细流程，涉及的组件怎么通信的？
这道题考察的是 k8s 内部组件通信。
k8s 创建一个 Pod 的详细流程如下： 
*(1) 客户端提交创建请求，可以通过 api-server 提供的 restful 接口，或者是通过 kubectl 命令行工具，支持的数据类型包括 JSON 和 YAML。
(2) api-server 处理用户请求，将 pod 信息存储至 etcd 中。
(3) kube-scheduler 通过 api-server 提供的接口监控到未绑定的 pod，尝试为 pod 分配 node 节点，主要分为两个阶段，预选阶段和优选阶段，其中预选阶段是遍历所有的 node 节点，根据策略筛选出候选节点，而优选阶段是在第一步的基础上，为每一个候选节点进行打分，分数最高者胜出。
(4) 选择分数最高的节点，进行 pod binding 操作，并将结果存储至 etcd 中。
(5) 随后目标节点的 kubelet 进程通过 api-server 提供的接口监测到 kube-scheduler 产生的 pod 绑定事件，然后从 etcd 获取 pod 清单，下载镜像并启动容器。
*整个事件流可以参考下图：

 

集群扩广遇到的挑战是什么
这道题主要考察在扩广 k8s 集群实现微服务容器化部署实际落地过程中遇到的挑战和踩过的坑有哪些，话题有点广，可以说的点其实挺多的，我主要从以下几个方面来阐述的。
部署的规范流程
*虽然说容器和虚拟机部署本质上没有多大区别，但还是有些许不同的。容器的可执行文件是一个镜像，而虚拟机的可执行文件往往是一个二进制文件如 jar 包或者是 war包，另外，由于容器隔离的不是特别彻底，在上文也有所阐述，针对这种情况，如何更准确获取 cgroups 给容器限定的 Memory 和 CPU 值，这给平台开发者带来相应的挑战。此外，在容器化部署时，作为用户而言，需要遵循相应的使用规范和流程，如每个 Pod 都必须设置资源限额和健康检测探针，在设置资源限额时，又不能盲目设置，需要依赖监控组件或者是开发者本身对自身应用的认知，进行相关经验值的设置。
*多集群调度
*对于如何管理多个 k8s 集群，如何进行跨集群调度、应用部署和资源对象管理，这对于平台本身，都是一个很大的挑战。
*调度均衡问题
*随着集群规模的扩大以及微服务部署的数量增加，同个计算节点，可以会运行很多 Pod，这个时候就会出现资源争用的问题，k8s 本身调度层面有两个阶段，分别是预选阶段和优选阶段，每个阶段都有对应的调度策略和算法，关于如何均衡节点之后的调度，这需要在平台层面上对调度算法有所研究，并进行适当的调整。


著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

docker中进程的监控

  Docker相比VM效率
   
  Docker集群管理一般会有哪些操作


2)容器业务规划处理相关
   容器化过程中, 讲述下对业务服务是怎么规划的(一般尽可能微服务化)
   容器化运维过程中,怎么进行灰度
   业务级的日志是怎么处理的

工作相关：
你在工作的过程中，遇到过你映像最深的是什么故障问题，你又是如何解决？

笔者回答：这个问题主要也是考你排查故障的思路及用到的相关命令工具，其每个人在工作中都会遇到各种各样的问题（不管是网络问题、应用配置问题、还是APP打开慢/网站打开慢）等等。你只要记住一个你映像最为深刻、最为典型的故障就行。笔者也遇到过各种问题，我在这里就是写出来，怕误导了大家。
你对现在运维工程师的理解和以及对其工作的认识
运维工程师在公司当中责任重大，需要保证时刻为公司及客户提供最高、最快、最稳定、最安全的服务
运维工程师的一个小小的失误，很有可能会对公司及客户造成重大损失
因此运维工程师的工作需要严谨及富有创新精神


监控、告警优化
运维服务质量
自动化
打包、灰度、发布、回滚
故障排查
备份和恢复
演练
SOW
过载保护、优化降级
故障：单机、多级、机房、城市
容量规划
幂等性

SRE团队要承担以下几类职责：可用性改进，延迟优化，性能优化，效率优化，变更管理，监控，紧急事务处理以及容量规划与管理。

负载均衡策略：
简单轮询算法
最先轮询策略
加权轮询策略
<Google SRE>读后感
 分布式环境运维大不同于传统运维
我的理解：在分布式环境下，系统的复杂度增大、维护目标增多，按照传统的手工或者半自动维护来做，是不行的。所以，需要转变思路：
事务性的工作工具化。比如：版本发布、服务器监控；
让系统自反馈。完善的监控告警机制，完善的日志记录和分析体制，可视化系统的健康状态，使得系统变得可追踪和调校；
分布式策略应对巨量运维对象。负载均衡、流控、数据完整性、批处理的变得不一样，需要重新设计和实践。同时，更要重视连锁式故障。
分布式系统的核心——分布式共识
分布式共识问题是指“在不稳定的通信环境下一组进程之间对某项事情达成一致的问题”。
分布式共识系统可以用来解决：领头人选举、关键共享状态、分布式锁等问题。或者绝对点，所有的分布式问题都应当考虑到分布式共识的问题。
分布式共识的理论基础和实现都不是很好理解，抽时间搞清楚是大有裨益的，这里罗列一下几个关键词：
拜占庭问题
可复制状态机
Paxos算法
Zookeeper
Chubby

有意识地破坏你的系统
不同于演练，而是真实生产系统，在可控范围内，人为制造故障，然后在有人值守的情况下，找到系统的短板和问题。这样等到真正的故障来临时，可以有章可循，快速解决问题。
主动暴露自己的不足好于别人突然揭发你，当然更重要的是要及时纠正不足。

拥抱风险
传统运维是厌恶风险的，但是开发和产品却更关注变化速度，他们都希望迭代速度越快越好，但是这回给系统运行带来风险，所以这天生是矛盾。
为了解决风险和变化的矛盾，google提出了SLI-->SLO-->SLA的机制。
SLI——服务质量指标，如：延时、吞吐量、错误率、可用性等
SLO——服务质量目标，服务的某个SLI的目标值，或者目标范围。比如：SLI<=目标值，min=
SLA——服务质量协议（Agreement），服务（SRE）和用户（开发、产品）之间的一个明确的、或者不明确的协议，描述了在达到或者没有达到SLO之后的后果。或者可以转化为先行的KPI，比如系统可用性99.99%等。
开发和运维针对某个系统协商好一个SLA后，大家有一个量化的指标，一旦出现冲突时，算一下，看看是否违反SLA，如果违反，那么就升级走流程。这样既灵活，也有章可循。如果开发团队牛逼，代码质量高或者运气好，你可以迭代快，反之你需要慢点来，间接地，大家都对线上系统负责了。

分布式系统

什么是分布式系统中的幂等性
最近很多人都在谈论幂等性，好吧，这回我也来聊聊这个话题，光看着俩字，一开始的确有点一头雾水，语文不好嘛，词太专业嘛，对吧
现如今我们的系统大多拆分为分布式SOA，或者微服务，一套系统中包含了多个子系统服务，而一个子系统服务往往会去调用另一个服务，而服务调用服务无非就是使用RPC通信或者restful，既然是通信，那么就有可能再服务器处理完毕后返回结果的时候挂掉，这个时候用户端发现很久没有反应，那么就会多次点击按钮，这样请求有多次，那么处理数据的结果是否要统一呢？那是肯定的！尤其再支付场景。

幂等性：就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。举个最简单的例子，那就是支付，用户购买商品使用约支付，支付扣款成功，但是返回结果的时候网络异常，此时钱已经扣了，用户再次点击按钮，此时会进行第二次扣款，返回结果成功，用户查询余额返发现多扣钱了，流水记录也变成了两条．．．

在以前的单应用系统中，我们只需要把数据操作放入事务中即可，发生错误立即回滚，但是再响应客户端的时候也有可能出现网络中断或者异常等等。

在增删改查4个操作中，尤为注意就是增加或者修改，
查询对于结果是不会有改变的，
删除只会进行一次，用户多次点击产生的结果一样
修改在大多场景下结果一样
增加在重复提交的场景下会出现

那么如何设计接口才能做到幂等呢？
方法一、单次支付请求，也就是直接支付了，不需要额外的数据库操作了，这个时候发起异步请求创建一个唯一的ticketId，就是门票，这张门票只能使用一次就作废，具体步骤如下：
1.	异步请求获取门票
2.	调用支付，传入门票
3.	根据门票ID查询此次操作是否存在，如果存在则表示该操作已经执行过，直接返回结果；如果不存在，支付扣款，保存结果
4.	返回结果到客户端
如果步骤4通信失败，用户再次发起请求，那么最终结果还是一样的

方法二、分布式环境下各个服务相互调用
这边就要举例我们的系统了，我们支付的时候先要扣款，然后更新订单，这个地方就涉及到了订单服务以及支付服务了。
用户调用支付，扣款成功后，更新对应订单状态，然后再保存流水。
而在这个地方就没必要使用门票ticketId了，因为会比较闲的麻烦
（支付状态：未支付，已支付）
步骤：
1、查询订单支付状态
2、如果已经支付，直接返回结果
3、如果未支付，则支付扣款并且保存流水
4、返回支付结果
如果步骤4通信失败，用户再次发起请求，那么最终结果还是一样的
对于做过支付的朋友，幂等，也可以称之为冲正，保证客户端与服务端的交易一致性，避免多次扣款。

最后来看一下我们的订单流程，虽然不是很复杂，但是最后在支付环境是一定要实现幂等性的

 


分布式事务
两阶段提交

三阶段提交


数据结构和算法

Python

osi七层模型

TCP/IP

tcp长短链接的使用场景


